% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{report} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% Share Figure and Table Numbering %%%
\makeatletter
\renewcommand*{\thetable}{\arabic{table}}
\renewcommand*{\thefigure}{\arabic{figure}}
\let\c@table\c@figure

%%% Code Listings %%%
\usepackage{color}
\usepackage{listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=2,
  commentstyle=\itshape,
  basicstyle=\ttfamily,
  morekeywords={models, lambda, forms},
keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
frame=shadowbox,
breaklines=true
}


\usepackage[parfill]{parskip} % Uncomment this to have no paragraph indentation
\usepackage{mathtools}
\usepackage[english]{babel}
\usepackage{graphicx}

%%% END Article customizations



%%% The "real" document content comes below...

\title{Automatic Star-rating Generation from Text Reviews}
\author{
  Chong-U Lim\\
  \texttt{culim@csail.mit.edu}
  \and
  Pablo Ortiz\\
  \texttt{portiz@csail.mit.edu}
  \and
 Sang-Woo Jun\\
  \texttt{wjun@csail.mit.edu}
}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle

\tableofcontents

\newpage
\chapter{Introduction}
For our final project, we designed a system that generates five-star ratings for a product based on a review of that product. Ratings are generated by classifying the overall sentiment of a product review on the five-star scale using the PMI-IR algorithm. In the actual implementation of the system, we constrained the domain of product reviews to those of mobile applications on the Google Play App store. It was necessary to constrain the system to a particular problem domain as different problem domains will produce different sentiments for the same words. The system we created can serve as a proof of concept for generating five-star ratings based on product reviews for products and services of various kinds.

\section{Motivation}


Accurate customer feedback is much sought after by commercial enterprises. The information is quite valuable and affects a comapny's bottom line by aiding in the design of new products/services or helping to fix those that have not been well-received. This being the  case, many companies invite their customers to submit reviews for products they have used. The format of these reviews can vary widely from the ``Like" format used by Facebook to lengthy surveys. Some formats, of course, are used more in practice than others.


One well-established format for customer reviews is that of five-star ratings paired with short text reviews. Feedback in this form allows a customer to both give an overall rating for a product/service and provide meaningful commentary about the product/service. Unfortunately, a problem related to the accuracy of the reviews comes up when feedback is formatted this way. A particular star rating can mean completely different things to two different customers. For example, suppose there is one customer who sees the world in black and white and another customer who sees the world along the full five-star gradient. A one-star review from the first customer could mean anything between minor dislike and absolute hatred. The content of his/her text review would likely shed light on that. A one-star review from the second customer would definitely indicate absolute hatred. Though this example is quite extreme, it illustrates a flaw inherent to this system of obtaining feedback: some star ratings will not match the corresponding sentiment seen in the accompanying text commentary. For a commercial enterprise looking to collect accurate feedback from its customer reviews, this should be a matter of much concern.


To acquire more accurate information from customer feedback, we propose the removal of five-star ratings from these review formats entirely. Instead, we propose that the star ratings be generated in a uniform fashion from the sentiment of the text commentary. To  realize this proposal, we created a analyzes customer reviews of mobile applications from the Google Play store.

\chapter{Background}

%%% BEGIN Chapter: Design
\chapter{Design}
\section{Data Collection}

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.6\textwidth]{figures/playstore.png}
 \caption{User Reviews on the Google Play Store}
\label{fig:playstore}
\end{figure}

Google does not supply any publicly available Application Programming Interfaces (APIs) to query for data or results on the Google Play Store. Also, in searching for user reviews for a given application, one has to first navigate to the associated page and is at first initially presented with only the first 10 reviews, with the rest only asynchronously provided when a user clicks on the paginated links at the bottom (Figure~\ref{fig:playstore}). 

\begin{figure}[h!]
  \centering
    \includegraphics[width=0.8\textwidth]{figures/user_review.png}
 \caption{User Reviews on the Google Play Store}
\label{fig:user_review}
\end{figure}

However, attempts to automated the querying for more results were blocked by Google. As such, we had to manually obtain the data by first clicking through all the provided pagination links at the bottom in order to load all the user reviews. After which, we made use of Google Chrome's View Source functionality to extract all DOM elements between the \verb|<html>| element. A python script was then used to locate each user review, and extract out 3 main features, namely, the \textbf{Review Title}, \textbf{Review Text} and the \textbf{Star-Rating} (Figure~\ref{fig:user_review}).

\section{Phrase Extraction}
\label{subsection:phrase_extraction}
\subsection{Parts-Of-Speech (POS) Tagging}
The text gathered as part of the \textbf{review text} often varies in length (i.e. number of sentences, number of words). Our aim is to extract out the important phrases in each review and use them to guide our calculation of the overall sentiment of the user's review. In order to do so, we first process the review text by splitting them into sentences, followed by determining the part-of-speech (POS) tags for each word in the sentence. 
\subsection{Pattern Matching}
\begin{table}[h]
	\centering
    \begin{tabular}{  l  l  l  l}
    \hline\hline
    	 & First Word & Second Word & \shortstack{Third Word \\ (Not Extracted} \\ \hline
	1. & JJ, JJS, JJR & NN, NNS & anything \\ \hline
	2. & RB, RBR, RBS &JJ, JJS, JJR & neither NN nor NNS \\ \hline
	3. & JJ, JJS, JJR & JJ, JJS, JJRS & neither NN nor NNS \\ \hline
	4. & NN, NNS & JJ, JJS, JJRS & neither NN nor NNS \\ \hline
	5. & RB, RBR, RBS &VB, VBD, VBN, VBG & anything \\ \hline
	6. & DT & JJ, JJS, JJRS & anything \\ \hline
	7. & VBZ & JJ, JJS, JJRS & anything \\ \hline
    \hline
    \end{tabular}
\caption{Patterns of POS Tags for 2-Word Phrase Extraction}
\label{fig:postags}
\end{table}

Given the tokenized form of the sentence, we proceed to extract 2-word phrases from the review via pattern matching against a set of phrase patterns, as shown in Table~\ref{fig:postags}. The patterns of POS tags are extended from an original list proposed by Turney~\cite{Turney2001}. Our extensions were required in order to better match style of reviews on the Google Play Store, and also to match the tokens used in the \textit{NLTK} library. One notable addition was the addition of \textit{superlative} adjectives (JJS), which we were emperically found o occur substantially in our dataset, with sentences such as \`` \textit{\dots this game is \textbf{the best} ! \dots}." We also added comparative adjectives (JJS) to our matched tags. Figure~\ref{fig:phrase_extraction} shows the results of our phrase extraction on a user review in our dataset.

\begin{figure}[h!]
  \centering
\begin{lstlisting}
text = "This is a great game but lags horribly. I'm constantly dying because it freezes up on me! Pleasseee do something to fix it!:)"
>>> get_phrases_from_text(text)
[[('a', 'DT'), ('great', 'JJ')], [('great', 'JJ'), ('game', 'NN')], [('constantly', 'RB'), ('dying', 'VBG')]]

\end{lstlisting}
 \caption{User Reviews on the Google Play Store}
\label{fig:phrase_extraction}
\end{figure}

\section{Phrase Sentiment}
In order to gain insight regarding the user's sentiment based on his or her review, we make use of the extracted phrases from 
Section~\ref{subsection:phrase_extraction} as a measure of a user's sentiment towards the application. The basis of extracting information from the phrases is derived from the mutual information of the words contained within the phrase, against known words that we identified as having either \textit{positive} or \textit{negative} sentiment polarity. 

\subsection{Pointwise Mutual Information (PMI)}
The Pointwise Mutual Information (PMI) between two words\cite{church1990}, is defined with the following equation:

% \begin{math}...\end{math}
\begin{equation*} PMI(word_1, word_2) = \log_2 \left(\frac{Pr[word_1 \: and \: word_2]}{Pr[word_1] \times Pr[word_2]}\right) \end{equation*}

In the equation, the term $Pr[word]$ refers to the probability of the word appearing if we were to sample randomly from a text corpus, while  $Pr[word_1 \: and \: word_2]$ refers to the probability of both words appearing together. The ratio between p(word1 \& word2) and p(word1) p(word2) is thus a measure of the degree of statistical dependence between the words. The log of this ratio is the information gain from one of the words when the other is observed. The PMI score has an additional property in which it assigns a proportionally higher score to the words that appear infrequently in a given corpus, but with a higher likelihood of appearing together in the event they do\cite{Vargas2010}. 

\subsection{Semantic Orientation}
The semantic orientation of a given phrase is thus given by the formula:
\begin{equation*} SO(phrase) = PMI(phrase, \verb|<positive>|) - PMI(phrase, \verb|<negative>|)\end{equation*}

In the formula, the terms \verb|positive| and \verb|negative| refer to words which are respectively associated with positive sentiments and negative sentiments. 

\subsection{PMI-IR}
In Turney's implementation, he made used of the the words \textit{"excellent"} and \textit{"negative"}. Also, he introduces a technique called PMI-IR (Information Retrieval) in order to estimate the PMI values by using hit counts returned from search engine queries. He estimates the semantic orientation using the formula:

\begin{equation*} SO(phrase) = \log_2 \left(\frac{hits(phrase \: NEAR \: ``excellent") \times hits(``poor") }{hits(phrase \: NEAR \: ``poor") \times hits(``excellent") }\right) \end{equation*}

The term \textit{NEAR} in the equation above is a search query modifier which only returns results in which the items are located within a fixed number of words between each other. 

As a basis for our implementation, we used a similar PMI-IR estimation for semantic orientation of the extracted phrases, but using Google as the search engine of choice, and replacing the \textit{NEAR} operator with Google's corresponding \textit{AROUND(n)} operator (where \text{n} indicates the maximum range of words of which the two items in the search could differ by.)

However, based on our initial findings, we identified two problems with this approach. Firstly, automated queries to Google go against its Terms of Service Agreement. Despite attempts to decrease the likelihood of being detected such as by limiting our queries to a random interval between 10-15 seconds, we got blocked after about 80-100 calls. A survey of other alternative search engines either resulted in similar limits enforced (Bing), or deprecated APIs (Yahoo, Altavista). This made the process a slow and cumbersome endeavour.

The second problem was associated with the accuracy of the calculated results, which are outlined in greater detail in Chapter~\ref{chapter:results}. In short, the results failed to convincingly associate phrases with the correct polarity, partly due to the fact that the Google Search API does not actually return accurate values for the number of hits.

\subsection{Corpus-Derived PMI}
In order to find a method of calculating SO scores for phrases quickly, and without limit, we turned towards an offline SO estimator which uses the \textit{NLTK} \verb|movie_reviews| corpus. The corpus is a collection of user reviews from the \textit{IMDB Movie Database} , and is separated into sentences associated with \textit{positive} and \textit{negative} reviews. In our implementation, we first created a probability distribution of words which appear in the \text{positive} reviews and \text{negative} reviews separately. Next, we estimated the semantic orientation of a phrase using the formula:

\begin{equation*} SO(word) = \log_2 \left(\frac{Pr_{pos}[word]}{Pr_{neg}[word]}\right) \end{equation*}

Where the term $Pr_{pos}[word]$ is the probability of occurence of the word $word$ using the frequency distribution model acquired from the \textit{positive} corpus. The term $Pr_{pos}[word]$ naturally refers to the corresponding definition associated with the \textit{negative} corpus. We can easily extend this to a phrase with two words, such as ``very annoying" by calculating $SO(``very") + SO(``annoying")$. This allows us to attain values such as $SO(`excellent`")=1.2432$, $SO(``poor")=-0.9219$, $SO(``very \: annoying")=-0.3952$ and $SO(``very \: happy")=0.6716$. Thus, this gives us a nice form in which positive phrases are given positive values, and negative phrases are given negative values. Also, the magnitude of a value indicates a stroner association with the polarity.

\subsection{Text Semantic Orientation}
Given that a review text often contains several sentences, which in part contain several phrases which match our phrase patterns, we calculate the semantic orientation of a given text by averaging the semantic orientation values of its constituent matched-phrases. We present the calculation of two reviews from our dataset, one corresponding to a positive user review (Figure~\ref{fig:positive_review}) and another corresponding to a negative user review (Figure~\ref{fig:negative_review}). We illustrate the phrase extracted together with its constituent POS tags and the results of the per-phrase semantic-orientation calculation and overall semantic orientation of the review.

\pagebreak
\subsubsection{Positive Review}
\begin{comment}
pprint(res_free[130])
{'original_index': 32,
 'phrases': [[(u'is', 'VBZ'), (u'such', 'JJ')],
             [(u'an', 'DT'), (u'entertaining', 'JJ')],
             [(u'entertaining', 'JJ'), (u'game', 'NN')],
             [(u'is', 'VBZ'), (u'great', 'JJ')],
             [(u'Another', 'DT'), (u'great', 'JJ')]],
 'rating-calculated': 5.0,
 'rating-user': 5.0,
 'so': 0.4126400904562006,
 'text': u'This is such an entertaining game that is great for killing time. Another great Angry Birds game :-)',
 'text-cls': 'pos',
 'title': u'Fantastic Game',
 'title-cls': 'pos'}

>>> so_2("is", "such")
0.15734872244647513
>>> so_2("an", "entertaining")
0.32014397089151714
>>> so_2("entertaining", "game")
0.385981805784978
>>> so_2("is", "great")
0.6650209890754402
>>> so_2("another", "great")
0.4515674226156673
\end{comment}
\begin{table}[h!]
	\centering
    \begin{tabular}{  l  l  c}
    \hline\hline
    	 Extracted Phrase & POS Tags & Semantic Orientation \\ \hline
	is such & VBZ JJ & 0.1573 \\ \hline
	an entertaining & DT JJ & 0.3201 \\ \hline
	entertaining game & JJ NN & -0.1939 \\ \hline \hline
	is great & VBZ JJ & 0.6650 \\ \hline \hline
	another great & DT JJ & 0.4515 \\ \hline \hline
	Average Semantic Orientation & & 0.4126\\ \hline
    \hline
    \end{tabular}
\caption{Semantic Orientation Calculation for a Positive Review}
\label{fig:positive_review}
\end{table}


\subsubsection{Negative Review}
\begin{comment}
pprint(bad_free[55])
{'original_index': 936,
 'phrases': [[(u'a', 'DT'), (u'big', 'JJ')],
             [(u'big', 'JJ'), (u'fan', 'NN')],
             [(u'a', 'DT'), (u'huge', 'JJ')],
             [(u'huge', 'JJ'), (u'problem', 'NN')],
             [(u"n't", 'RB'), (u'work', 'VB')],
             [(u'even', 'RB'), (u'uninstalled', 'VBD')],
             [(u'then', 'RB'), (u'reinstalled', 'VBD')],
             [(u'again', 'RB'), (u'help', 'VB')],
             [(u"n't", 'RB'), (u'stay', 'VB')]],
 'rating-calculated': 1.0,
 'rating-user': 2.0,
 'so': -0.29789422119460257,
 'text': u"I love this game a lot! I'm a big fan and an addict to this game but recently I have been Facing a huge problem now I open this game it doesn't work it opens and then closes straight away I even uninstalled it and then reinstalled it but no difference same thing again help me please I love this can't stay without playing it",
 'text-cls': 'neg',
 'title': u'Fix it !!!',
 'title-cls': 'neg'}

>>> so_2("a", "big")
-0.33098922965584293
>>> so_2("big", "fan")
-0.7056408179636935
>>> so_2("a", "huge")
-0.23955015985152298
>>> so_2("huge", "problem")
-0.7483314776169897
>>> so_2("not", "work")
-0.06760705836956686
>>> so_2("even", "uninstalled")
-0.26451873835339673
>>> so_2("then", "reinstsalled")
-0.3341268897682953
>>> so_2("again", "help")
0.07927221248239999
>>> so_2("not", "stay")
-0.06955583165451482

\end{comment}
\begin{table}[h]
	\centering
    \begin{tabular}{  l  l  c }
    \hline\hline
    	 Extracted Phrase & POS Tags & Semantic Orientation \\ \hline
	 a big & DT JJ & -0.3309 \\ \hline
	big fan & JJ NN & -0.7056 \\ \hline
	a huge & DT JJ & -0.2395 \\ \hline \hline
	huge problem & JJ NN & -0.7483 \\ \hline \hline
	not work &  RB VBD & -0.0676 \\ \hline \hline
	even uninstalled & RB VBD  & -0.2645 \\ \hline \hline
	then reinstalled &  RB VBD & 0.3341 \\ \hline \hline
	again help &  RB VB  & 0.0792 \\ \hline \hline
	not stay & RB VB & -0.0695\\ \hline \hline
	Average Semantic Orientation & & -0.2978 \\ \hline
    \hline
    \end{tabular}
\caption{Semantic Orientation Calculation for a Negative Review}
\label{fig:negative_review}
\end{table}

\section{Text Polarity}


%%% END Chapter: Design


\chapter{Results}
\label{chapter:results}
	\section{PMI-IR}

Below are the results for the free applications only.

\begin{verbatim}

--------------------------------------------------------------------------------
Free Apps

Review Index   Author's Star Rating   Generated Star-Rating   Delta(Star Rating)
      0                2.0                    1.0 	                  1.0
      1                1.0                    5.0                   -4.0
      2                5.0                    1.0                    4.0
      3                2.0                    1.0                    1.0
      4                1.0                    3.0                   -2.0
      5                5.0                    5.0                    0.0
      6                5.0                    3.0                    2.0
      7                5.0                    1.0                    4.0
      8                5.0                    3.0                    2.0
      9                5.0                    3.0                    2.0
     10                1.0                    1.0                    0.0
     11                1.0                    3.0                   -2.0
     14                5.0                    3.0                    2.0
     20                4.0                    3.0                    1.0
     21                5.0                    5.0                    0.0
     22                2.0                    3.0                   -1.0
     23                3.0                    3.0                    0.0
     24                5.0                    5.0                    0.0
     27                5.0                    3.0                    2.0
     28                5.0                    3.0                    2.0
     29                5.0                    3.0                    2.0
     32                5.0                    3.0                    2.0
     34                1.0                    3.0                   -2.0
     35                4.0                    1.0                    3.0
     36                5.0                    3.0                    2.0
     37                5.0                    3.0                    2.0
     38                5.0                    3.0                    2.0
     39                5.0                    3.0                    2.0
     41                2.0                    5.0                   -3.0
     42                5.0                    3.0                    2.0
     43                5.0                    3.0                    2.0
     44                5.0                    5.0                    0.0
     45                4.0                    3.0                    1.0
     46                1.0                    1.0                    0.0
     48                5.0                    3.0                    2.0
     49                5.0                    5.0                    0.0

Precision = 22.22%
--------------------------------------------------------------------------------

\end{verbatim}

The results are for Yahoo! and Bing were not kept, and, thus, will not be shown.

	\section{PMI-CD}

Below are the results for the free applications.

\begin{verbatim}

--------------------------------------------------------------------------------
Free Apps

Review Index   Author's Star Rating   Generated Star-Rating   Delta(Star Rating)
      0                2.0 	               4.0                      -2.0
      1                1.0                    4.0                   -3.0
      2                5.0                    4.0                    1.0
      3                2.0                    4.0                   -2.0
      4                1.0                    4.0                   -3.0
      5                5.0                    4.0                    1.0
      6                5.0                    4.0                    1.0
      7                5.0                    4.0                    1.0
      8                5.0                    4.0                    1.0
      9                5.0                    4.0                    1.0
     10                1.0                    4.0                   -3.0
     11                1.0                    4.0                   -3.0 
     14                5.0                    4.0                    1.0
     20                4.0                    4.0                    0.0
     21                5.0                    4.0                    1.0
     22                2.0                    4.0                   -2.0
     23                3.0                    4.0                   -1.0
     24                5.0                    4.0                    1.0
     27                5.0                    4.0                    1.0
     28                5.0                    4.0                    1.0
     29                5.0                    4.0                    1.0
     32                5.0                    4.0                    1.0
     34                1.0                    4.0                   -3.0
     35                4.0                    4.0                    0.0
     36                5.0                    4.0                    1.0
     37                5.0                    4.0                    1.0
     38                5.0                    3.0                    2.0
     39                5.0                    4.0                    1.0
     41                2.0                    4.0                   -2.0
     42                5.0                    4.0                    1.0
     43                5.0                    4.0                    1.0
     44                5.0                    4.0                    1.0
     45                4.0                    4.0                    0.0
     46                1.0                    4.0                   -3.0
     48                5.0                    4.0                    1.0
     49                5.0                    4.0                    1.0

Precision = 8.333%
--------------------------------------------------------------------------------

\end{verbatim}

Below are the results for the paid applications.

\begin{verbatim}

--------------------------------------------------------------------------------
Paid Apps

Review Index   Author's Star Rating   Generated Star-Rating   Delta(Star Rating)
      0                3.0                    4.0                   -1.0
      1                5.0                    4.0                    1.0
      2                3.0                    4.0                   -1.0
      3                3.0                    4.0                   -1.0
      4                5.0                    4.0                    1.0
      5                3.0                    4.0                   -1.0
      6                5.0                    4.0                    1.0
      7                1.0                    4.0                   -3.0
      8                1.0                    3.0                   -2.0
      9                4.0                    4.0                    0.0
     10                1.0                    3.0                   -2.0
     11                3.0                    4.0                   -1.0
     12                5.0                    4.0                    1.0
     13                2.0                    4.0                   -2.0
     14                4.0                    4.0                    0.0
     15                1.0                    4.0                   -3.0
     16                2.0                    4.0                   -2.0
     17                2.0                    4.0                   -2.0
     18                5.0                    4.0                    1.0
     19                1.0                    4.0                   -3.0
     20                3.0                    4.0                   -1.0
     21                4.0                    4.0                    0.0
     22                3.0                    4.0                   -1.0
     23                3.0                    3.0                    0.0
     24                5.0                    4.0                    1.0
     25                4.0                    4.0                    0.0
     26                3.0                    4.0                   -1.0
     27                5.0                    3.0                    2.0
     29                2.0                    4.0                   -2.0
     30                1.0                    3.0                   -2.0
     31                1.0                    4.0                   -3.0
     32                2.0                    4.0                   -2.0
     34                2.0                    3.0                   -1.0
     35                1.0                    4.0                   -3.0
     36 	              1.0                    4.0                   -3.0
     37                1.0                    4.0                   -3.0
     38                2.0                    4.0                   -2.0
     39                5.0                    4.0                    1.0
     41 	              4.0                    4.0                    0.0
     42                5.0                    4.0                    1.0
     43                1.0                    4.0                   -3.0
     44                3.0                    4.0                   -1.0
     45                1.0                    4.0                   -3.0
     46                5.0                    3.0                    2.0
     47                2.0                    4.0                   -2.0
     48                3.0                    4.0                   -1.0
     49                2.0                    4.0                   -2.0

Precision = 12.77%
--------------------------------------------------------------------------------

\end{verbatim}

	\section{PMI-CUE}

\begin{verbatim}

--------------------------------------------------------------------------------
Free Apps

Rating Distribution
1.0 	#= 80 	%= 6.56275635767
2.0 	#= 62 	%= 5.08613617719
3.0 	#= 96 	%= 7.8753076292
4.0 	#= 224 	%= 18.3757178015
5.0 	#= 752 	%= 61.6899097621

By-Rating Analysis
( 1.0 )
# Correct Title      Polarizations:  23 	28.75 %
# Correct Text       Polarizations:  45 	56.25 %
# Correct Title/Text Polarizations:  16 	20.0 %
# Correct w.r.t. SO  Polarizations:  47 	58.75 %
Minimum Semantic Orientation      :  -4.10800522164
Maximum Semantic Orientation      :  4.32499847078
Average Semantic Orientation      :  -0.11806191259
Percantage of Good Ratings        :  47.5 %


( 2.0 )
# Correct Title      Polarizations:  20 	32.2580645161 %
# Correct Text       Polarizations:  28 	45.1612903226 %
# Correct Title/Text Polarizations:  11 	17.7419354839 %
# Correct w.r.t. SO  Polarizations:  34 	54.8387096774 %
Minimum Semantic Orientation      :  -7.89135107031
Maximum Semantic Orientation      :  0.85747362778
Average Semantic Orientation      :  -0.646424002864
Percantage of Good Ratings        :  83.8709677419 %


( 3.0 )
# Correct Title      Polarizations:  63 	65.625 %
# Correct Text       Polarizations:  55 	57.2916666667 %
# Correct Title/Text Polarizations:  39 	40.625 %
# Correct w.r.t. SO  Polarizations:  54 	56.25 %
Minimum Semantic Orientation      :  -5.30069117426
Maximum Semantic Orientation      :  1.82577891005
Average Semantic Orientation      :  -0.183704238283
Percantage of Good Ratings        :  71.875 %


( 4.0 )
# Correct Title      Polarizations:  150 	66.9642857143 %
# Correct Text       Polarizations:  147 	65.625 %
# Correct Title/Text Polarizations:  91 	40.625 %
# Correct w.r.t. SO  Polarizations:  114 	50.8928571429 %
Minimum Semantic Orientation      :  -4.81854773522
Maximum Semantic Orientation      :  7.18992078279
Average Semantic Orientation      :  0.130427122314
Percantage of Good Ratings        :  75.8928571429 %


( 5.0 )
# Correct Title      Polarizations:  570 	75.7978723404 %
# Correct Text       Polarizations:  509 	67.6861702128 %
# Correct Title/Text Polarizations:  400 	53.1914893617 %
# Correct w.r.t. SO  Polarizations:  493 	65.5585106383 %
Minimum Semantic Orientation      :  -8.19453865845
Maximum Semantic Orientation      :  9.47057572679
Average Semantic Orientation      :  0.114342450064
Percantage of Good Ratings        :  31.7819148936 %


Calculated Star Rating Success%: 46.5955701395
--------------------------------------------------------------------------------

\end{verbatim}

\begin{verbatim}

--------------------------------------------------------------------------------
Paid Apps

Rating Distribution
1.0 	#= 350 	%= 19.9771689498
2.0 	#= 91 	%= 5.19406392694
3.0 	#= 212 	%= 12.100456621
4.0 	#= 343 	%= 19.5776255708
5.0 	#= 751 	%= 42.8652968037

By-Rating Analysis
( 1.0 )
# Correct Title      Polarizations:  144 	41.1428571429 %
# Correct Text       Polarizations:  194 	55.4285714286 %
# Correct Title/Text Polarizations:  70 	20.0 %
# Correct w.r.t. SO  Polarizations:  170 	48.5714285714 %
Minimum Semantic Orientation      :  -8.29669100827
Maximum Semantic Orientation      :  8.47343869582
Average Semantic Orientation      :  -0.16184925747
Percantage of Good Ratings        :  44.8571428571 %


( 2.0 )
# Correct Title      Polarizations:  46 	50.5494505495 %
# Correct Text       Polarizations:  46 	50.5494505495 %
# Correct Title/Text Polarizations:  27 	29.6703296703 %
# Correct w.r.t. SO  Polarizations:  37 	40.6593406593 %
Minimum Semantic Orientation      :  -7.43835455131
Maximum Semantic Orientation      :  4.51920906072
Average Semantic Orientation      :  -0.174449181627
Percantage of Good Ratings        :  79.1208791209 %


( 3.0 )
# Correct Title      Polarizations:  145 	68.3962264151 %
# Correct Text       Polarizations:  131 	61.7924528302 %
# Correct Title/Text Polarizations:  82 	38.679245283 %
# Correct w.r.t. SO  Polarizations:  121 	57.0754716981 %
Minimum Semantic Orientation      :  -3.6766697051
Maximum Semantic Orientation      :  4.41430787775
Average Semantic Orientation      :  0.0859199580954
Percantage of Good Ratings        :  70.2830188679 %


( 4.0 )
# Correct Title      Polarizations:  192 	55.9766763848 %
# Correct Text       Polarizations:  224 	65.306122449 %
# Correct Title/Text Polarizations:  129 	37.6093294461 %
# Correct w.r.t. SO  Polarizations:  206 	60.0583090379 %
Minimum Semantic Orientation      :  -4.25449167662
Maximum Semantic Orientation      :  9.47057572679
Average Semantic Orientation      :  0.187845557391
Percantage of Good Ratings        :  71.7201166181 %


( 5.0 )
# Correct Title      Polarizations:  511 	68.0426098535 %
# Correct Text       Polarizations:  502 	66.844207723 %
# Correct Title/Text Polarizations:  341 	45.4061251664 %
# Correct w.r.t. SO  Polarizations:  420 	55.9254327563 %
Minimum Semantic Orientation      :  -7.96369454305
Maximum Semantic Orientation      :  8.32073661216
Average Semantic Orientation      :  0.110658084853
Percantage of Good Ratings        :  28.0958721704 %


Calculated Star Rating Success%: 47.6598173516
--------------------------------------------------------------------------------

\end{verbatim}

Below are the results for the free applications after training the thresholds using SVMs.

\begin{verbatim}

--------------------------------------------------------------------------------
Free Apps

-----------------------------------------
Assuming we correctly classify the the positive reviews, if we use 
semantic-orientation to calculate the exact star rating, we get 
the following results:

Accuracy: 0.70 (+/- 0.00)

-----------------------------------------
Assuming we correctly classify the the negative reviews, if we use 
semantic-orientation to calculate the exact star rating, we get 
the following results:

Accuracy: 0.58 (+/- 0.03)

Paid Apps
-----------------------------------------
Assuming we correctly classify the the positive reviews, if we use 
semantic-orientation to calculate the exact star rating, we get 
the following results:

Accuracy: 0.57 (+/- 0.00)

-----------------------------------------
Assuming we correctly classify the the negative reviews, if we use 
semantic-orientation to calculate the exact star rating, we get 
the following results:

Accuracy: 0.79 (+/- 0.00)

--------------------------------------------------------------------------------
\end{verbatim}

\chapter{Analysis}
	\section{PMI-IR}

Talk about difficulties. (Why it didn't work. Why we tried it, etc.)
The great success of this was discovering that it was not a good choice for a fast
project.

	\section{PMI-CD}

Talk about difficulties. (Why it didn't work. Why we tried it, etc.)
We did better with this approach than the previous one but it still was not good enough.

	\section{PMI-CUE}

Talk about why it works. Talk about things we observed from the data. (We don't have enough
data to make general conclusions). Considerable improvement over both methods. Training the
thresholds with SVMs made this even better.

\chapter{Conclusion}

\appendix
\chapter{Datasets}


\bibliographystyle{plain}
\bibliography{references}

\end{document}
